{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697ea0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# NLP libraries\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b22a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the listings data set\n",
    "\n",
    "listings_data = pd.read_csv('/home/rreinhaus/code/rreinhaus/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c292e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating description and superhost dataframe file\n",
    "\n",
    "superhost_description = listings_data[['id','host_is_superhost', 'description']] \n",
    "superhost_description = superhost_description[superhost_description['host_is_superhost'] == 't']\n",
    "superhost_description.drop(columns=['host_is_superhost'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782f9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrading the stopwords seen manually\n",
    "\n",
    "additional_words = ['flat', 'stay',\n",
    "                    'would','london','br',\n",
    "                    'di', 'la','b',\n",
    "                   'molto','casa','il', \n",
    "                    'un','con','una',\n",
    "                   'de', 'et','br','la','tr√®s',\n",
    "                   'est','le','und', 'en',\n",
    "                   'lovely', 'place', 'really','recommend',\n",
    "                   'host', 'room','apartment','highly recommended',\n",
    "                    'studio', 'house', 'bedroom', 'notting','hill','home', 'thing','note'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2258affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop = additional_words + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f62d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard cleaning function\n",
    "def clean(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = str(text)\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(new_stop) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c5fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "superhost_description['clean_description']= superhost_description['description'].apply(clean)\n",
    "superhost_description['clean_description'] = superhost_description['clean_description'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f52cf508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.6,ngram_range = (2,2))\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(superhost_description['clean_description'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=1)\n",
    "\n",
    "lda_vectors = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa888450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('guest access', 500.6374922506565), ('minute walk', 438.59608879823924), ('double bed', 314.3629507036205), ('min walk', 306.3642195818883), ('fully equipped', 258.2390663521639), ('walking distance', 234.17633786158166), ('open plan', 230.99228833634507), ('tube station', 224.29974914117753), ('transport link', 196.74974283900156), ('equipped kitchen', 194.97747302840224)]\n"
     ]
    }
   ],
   "source": [
    "# Checking the result\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a63604",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    for i in topic.argsort()[:-10 - 1:-1]:\n",
    "        keywords[vectorizer.get_feature_names()[i]] = topic[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "224abc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the final csv file to deploy on Google Cloud\n",
    "\n",
    "solution = []\n",
    "\n",
    "for key in keywords.keys():\n",
    "    solution.append(key)\n",
    "    \n",
    "keywords_final={}\n",
    "keywords_final['keywords'] = solution\n",
    "nlp_description = pd.DataFrame(keywords_final) \n",
    "description_london = nlp_description.to_csv('description_london.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
