{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5519a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP libraries\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e4d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the listings data set\n",
    "\n",
    "listings_data = pd.read_csv('/home/rreinhaus/code/rreinhaus/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37371149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating title and superhost dataframe file\n",
    "\n",
    "superhost_title = listings_data[['id','host_is_superhost', 'name']] \n",
    "superhost_title = superhost_title[superhost_title['host_is_superhost'] == 't']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3903de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "superhost_title.drop(columns=['host_is_superhost'], inplace=True)\n",
    "superhost_title['title'] = superhost_title['name']\n",
    "superhost_title.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf238089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrading the stopwords seen manually\n",
    "\n",
    "additional_words = ['flat', 'stay',\n",
    "                    'would','london','br',\n",
    "                    'di', 'la','b',\n",
    "                   'molto','casa','il', \n",
    "                    'un','con','una',\n",
    "                   'de', 'et','br','la','tr√®s',\n",
    "                   'est','le','und', 'en',\n",
    "                   'lovely', 'place', 'really','recommend',\n",
    "                   'host', 'room','apartment','highly recommended',\n",
    "                    'studio', 'house', 'bedroom', 'notting','hill','home'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6573c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop = additional_words + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c0d3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard cleaning function\n",
    "def clean(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = str(text)\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(new_stop) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "caa6a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "superhost_title['clean_title']= superhost_title['title'].apply(clean)\n",
    "superhost_title['clean_title'] = superhost_title['clean_title'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a564d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.6,ngram_range = (1,1))\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(superhost_title['clean_title'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=1)\n",
    "\n",
    "lda_vectors = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e415be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('double', 711.349302759554), ('bed', 516.514244795802), ('central', 463.4720756516208), ('private', 448.38933604766953), ('garden', 426.5251510990988), ('spacious', 398.4714736644875), ('modern', 376.8614868647855), ('bright', 334.8275231714085), ('near', 312.5965828544845), ('cosy', 305.40396296539996)]\n"
     ]
    }
   ],
   "source": [
    "# Checking the result\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2daf1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    for i in topic.argsort()[:-10 - 1:-1]:\n",
    "        keywords[vectorizer.get_feature_names()[i]] = topic[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe75d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the final csv file to deploy on Google Cloud\n",
    "\n",
    "solution = []\n",
    "\n",
    "for key in keywords.keys():\n",
    "    solution.append(key)\n",
    "    \n",
    "keywords_final={}\n",
    "keywords_final['keywords'] = solution\n",
    "nlp_title = pd.DataFrame(keywords_final) \n",
    "title_london = nlp_title.to_csv('title_london.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
